
\section*{Motivation and Key Research Questions}

The evolution of autonomy has revealed that the humans need to be inextricably involved in all dimensions of autonomous systems, not 
just managing those systems, but seamlessly integrating human capabilities, human information gathering, and human decision making.
\begin{center}
\parbox[c]{6in}{
{\em ``$\ldots$ the true value of unmanned systems is not to provide a direct human replacement, but rather to extend and complement human capability.''} \\
\hspace*{20pt} DSB Task Force Report, The Role of Autonomy in DoD Systems, 2012.
}
\end{center}
The DSB asserts that the benefits of Autonomy lie in unlimited persistence, reducing risk to humans, and reducing cognitive load.
Autonomy should in no way eliminate or reduce human capabilities.  This shifts thinking so that autonomy becomes a capability to
be integrated into a complex human-machine system,  rather than a functional replacement for a human.

With this conceptual shift, how can autonomy integrate into human-machine systems so that they maximize the 
performance of the system as a whole?  Insight into system performance requires measures and models of human performance 
both standalone and in the presence of autonomy.  Success will provide the capability to extend performance to systems that are multi-scale
networks of humans and autonomy.

Beyond performance, it is essential to have
guarantees that autonomous systems operate correctly within bounds set by human oversight, not specifications or requirements.
\begin{center}
\parbox[c]{6in}{
{\em ``Autonomous and semi-autonomous weapon systems shall be designed to allow 
commanders and operators to exercise appropriate levels of human judgment over the use of force.''}
\hspace*{20pt} A. B. Carter, DoD Directive 3000.09, November 21, 2012
}
\end{center}
This becomes increasingly difficult as autonomy grows in complexity, scope, and scale.  Advances are needed in 
the design of human-autonomy interaction, to ensure that autonomy reflects operator and command intent.  
Advances are also needed in proving the correctness of autonomous systems.  This must include the correctness of
humans, as their capabilities and tasks are networked into autonomy and will often serve as inputs to 
autonomous capabilities.

%Ensure that autonomy doesn’t compromise our humanity
%\begin{center}
%\parbox[c]{6in}{
%{\em ``To comply with international humanitarian law, fully autonomous weapons would need human qualities that they inherently lack.''} \\
%\hspace*{20pt} Human Rights Watch, “Losing Humanity”, November 19, 2012
%%}
%\end{center}

Because autonomy is evolving toward human collaboration, capability enhancement, and complex systems, 
new definitions of autonomy are needed to guide innovation and set goals.  The DoD Priority Steering
council recently defined autonomy as the ``capability and freedom to self-direct to achieve mission objectives''.
They also put forth that:
\begin{center}
\parbox[c]{6in}{
{\em ``Military Power in the 21st Century will be defined by our ability to adapt---this is THE hallmark of autonomy''
} \\
 \hspace*{20pt} DoD Priority Steering Council, Nov. 2012
}
\end{center}
The role of science and technology development in autonomy is to meet this definition of autonomy
while integrating humans, resolving conflicts between self-direction and correctness and 
ensuring that adaptation reflects human decisions.

% RB footnote?
The authors note that this thinkpiece focuses on how science and technology can contribute to achieving autonomy goals related to human collaboration in autonomous systems.
As such, it does not focus on acquisition, security, policy, or law.

\subsection*{Science and Technology Research Questions:}

An analysis of the requirements and risks reveals technical challenges to overcome and capability gaps to fill in order to
fully integrate humans into collaborative autonomy.  

%Key Technical Challenge Areas/Gaps
%Human-Autonomy Interaction and Collaboration
%Scalability
%Machine Intelligence
%Verification and Validation

\begin{itemize}
\item {\em How do we model, verify, and utilize humans as collaborative decision makers and actors in correct-by-construct autonomous systems?}
\end{itemize}

%\mc{TODO to write para for this one.}

Many automated systems today are designed primarily with automation in mind, not necessarily human interaction, leading to sub-optimal or incorrect integrated performance. 
%The ultimate success of many autonomous systems is intimately tied to interactions with a human. 
While the typical stated goal of autonomy is to remove the human element from particular tasks, it is critical to realize that the addition of autonomy simply moves humans to a different point/level of interaction with the autonomy; the human is typically not fully removed. As such, one must consider the autonomy+human as an integrated ‘system’ when evaluating performance, robustness, and effectiveness. The ultimate success of many autonomous systems is intimately tied to interactions with a human. 

Modeling even a portion of human capabilities will enable the ability to plan, optimize, and analyze an integrated human-autonomy system. Probabilistic modeling of human capabitilies is reaching a maturity level that could enable human-machine interactions to be more prospective, rather than reactive, which has typically been the characteristic of previous research on humans and automation. Importantly, the ability to probabilistically model human capabilities would enable the concept of `correctness' to be considered more deeply, such as with formal Verification and Validation methods. 

\begin{itemize}
\item {\em How do we create multi-scale, model-based autonomy (controllers, communication, and computation) that scale to the battlespace?}
\end{itemize}

Emergent autonomous systems cannot be thought of simply as controllers that automate functions.  Rather, they are networks of humans and machines that
perform heterogeneous complex tasks, such as data integration, navigation, target detection, and distributed sensing.  The ``controllers'' for 
autonomous capabilities must include computation and communication, making the human-machine network a distributed computing system with a 
network protocol.  This must include human computation for tasks in which humans exceed machines, such as language translation and 
object classification in images.  It must also include protocols for humans to communicate with autonomy. 

For complex, human-machine systems, model-based autonomy must be multi-scale, i.e.~define properties and invariants at multiple spatial and temporal scale
and integrate or link the scales into the battlespace view.  Autonomy must be decomposed into multiple models.  First, 
the state space of a human-machine network is so large as to be unsolvable in practice.  
Also, models must be concise and represent related concepts to produce meaningful correctness guarantees and result in controllers.
Autonomy will consist of a hierarchical network of models that are solved in detail individually and summarized to be integrated
into higher-level models.

\begin{itemize}
\item {\em How do we co-design complex mission systems to optimally and acceptably incorporate human and autonomy decision-makers and actors?}
\end{itemize}

% \ella{TODO to write para for this one.}

As systems more tightly integrate human and machine elements, the systems engineering process must evolve
to provide solutions that optimally or acceptably {\em{co-design}} the system over both humans and autonomy.
The traditional systems engineering process translates requirements to designs to implementations.  A fundamental
assumption of this process is that we can create and alter product design and implementation as needed to meet the requirements.
This assumption must be relaxed to account properly for humans whose capabilities are extremely versatile and adaptive but who cannot be 
``redesigned'' to meet requirements except through careful training.  The diversity inherently present in co-designed 
human-autonomy systems will requires new models to better accommodate human system elements and a more model-based approach to systems engineering than is used today.  

The co-designed human-autonomy system will be comprised of autonomy elements with
hardware and software customized to perform particular tasks, e.g., persistent surveillance, 
and humans expected to have received customized training to perform particular tasks, 
e.g., adapt mission goals based on incoming information.  Mission success is contingent on acceptable performance
by both.  This description is sufficiently general to fit into today's paradigms; the difference is that today
systems engineering focuses strictly on design and implementation of the machine systems (the autonomy), leaving
consideration of how these machines interact with humans (apart from graphical user interfaces) 
to be determined once the system is implemented. 

A co-designed system will infuse models of humans and autonomy throughout all phases of system engineering.
The products of the co-design system engineering process will then include both designs and implementations of autonomy 
elements that have been verified to exactly match their corresponding requirements and translations 
of human element requirements (roles and responsibilities) to training protocols along with metrics
used to verify that human performance has reached level(s) required by the overall system.  Validation of the 
co-designed system will then involve tests with fully-verified autonomy and fully-trained human actors engaged in
realistic deployment scenarios.

